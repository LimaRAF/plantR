---
title: "A tutorial on how to use __plantR__"
date: "`r format(Sys.time(), '%d %B %Y')`"

author: 
  - Renato A. F. de Lima^[Naturalis Biodiversity Center and Universidade de São Paulo, https://github.com/LimaRAF], Sara R. Mortara^[Jardim Botânico do Rio de Janeiro, https://github.com/saramortara] and Andrea Sánchez-Tapia^[Jardim Botânico do Rio de Janeiro,https://github.com/AndreaSanchezTapia]
output:
    github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load, echo = FALSE, eval = TRUE, include=FALSE}
devtools::load_all() # for development
```


<br/><br/>

# Introduction

This tutorial provides the details and explanations on the functions related to data
download, editing and validation using the __plantR__ workflow. For each of these steps, we present the functions and their options in more details so that their goals can be understood and so that these functions can be adapted and applied by the user, even outside the proposed workflow. 

Let's first install and load the package from [GitHub](https://github.com) with:

```{r, eval = F}
remotes::install_github("LimaRAF/plantR")
library("plantR")
```

<br/><br/>

# Data entry

You can download species occurrence data directly from R, using the functions
provided by __plantR__ or by other R packages. For this tutorial, we are going to
use the __plantR__ function `rspeciesLink()`, which downloads data from
[CRIA](http://www.cria.org.br/) (Centro de Referência em Informação Ambiental).
For a detailed tutorial of how to download data from different sources, check
[here]<!--(#INCLUDE HERE LINK TO SARA'S DETAILED TUTORIAL). -->

You can also use .csv files containing your own data or data downloaded manually
from online data repositories, as long as the column names are named following
DarwinCore standards. See function `fixField()` below for more details on
standard columns names.

## Downloading occurrence data with __plantR__

We will use as an example a dataset downloaded from speciesLink, using the
function `rspeciesLink()`, which allows a variety of ways on how to search for
data. In this tutorial, we will use data for two common Neotropical trees:

```{r, eval = TRUE}
spp <- c("Trema micrantha",
        "Casearia sylvestris")
```

After defining the species name we proceed to the download of occurrence data.
Here, we will use only herbarium plant specimens (i.e. vouchers) for the names
listed above, including the list of synonyms accepted in the List of Species of
the Brazilian Flora 2020 project (this may take a few minutes):

```{r, eval = FALSE}
example <- rspeciesLink(species =  spp,
                        Scope = "plants",
                        basisOfRecord = "PreservedSpecimen",
                        Synonyms = "flora2020")
is(example$data)
```

The occurrence data is now stored in the object `example`. We can inspect how
many occurrences were downloaded (`r nrow(example$data)` records and
`r ncol(example$data)` fields):


```{r, eval = FALSE}
dim(example$data)
```

If the data download is taking too long, you can use the result of the same search performed in June 2020 and stored within __plantR__ using the command `data(example)`.


## Preparing the input data: function `fixField()`

Before we can start to process the input data, we need to be sure that our input
data has all the required fields and that they are in the required format.

We use the function `fixField()` to set up the required and optional fields and
to drop fields without essential information for the data processing and
validation. We save the output of the function in an object with a different
name (`'occs'`).

```{r, eval = FALSE}
occs <- fixField(example$data, origin = "splink")
dim(occs)
```

Note that the function returns some warning messages. 

```r
Warning messages:
1: In fixField(example$data, origin = "splink") :
  Required field(s) 'county' was(were) replaced by 'municipality'
2: In fixField(example$data, origin = "splink") :
  The following field(s) was(were) removed: 
record_id
barcode
imagecode
geoFlag
preparationType
previousCatalogNumber
continentOcean
relatedCatalogItem
```

It is **very** important
to understand carefully these warnings before we can continue.

The first warning says that <!--the name of the column header 'scientifname',
provided in the input data, was replaced by the standard name 'scientificName',
the standard name used by __plantR__. The second warning also reports that--> a
required header name (`'county'`) was replaced by a standard header name,
`'municipality'` in this case.
The second warning is less important because it relates to optional fields. 
`fixFields()` removes the columns that belong to optional fields.


<br/><br/>

# Data editing

## Standardizing people names, collector number, dates and collection codes

Particularly when working with data coming from multiple sources, it
is important to standardize the notation used by different collections and
sometimes by different collectors within the same collection.

We first create the new columns that will receive the edited fields.

```{r, eval = FALSE}
occs$recordedBy.new <- occs$recordedBy
occs$recordNumber.new <- occs$recordNumber
occs$identifiedBy.new <- occs$identifiedBy
occs$year.new <- occs$year
occs$yearIdentified.new <- occs$yearIdentified
```
The year of collection is sometimes stored on the field 'eventDate' and not on
the field 'year'. In this case, we should replace all missing information from
the field 'year' by the information stored in the field 'eventDate'. Since this
is not the case here, we process to the next data processing step.  <!-- checar isto -->

We then prepare the new fields we created using functions `fixName()`,
`colNumber()` and `getYear()`. We chose to remove all species characters from
authors and identifier names (argument `special.char = FALSE`), which is the
indicated option for further data processing and validation. We also set the
characters that will represent occurrences without number of collection ("s.n.")
and without the year of collection and identification ("n.d.").

```{r, eval = FALSE}
occs$recordedBy.new <- fixName(occs$recordedBy, special.char = FALSE)
occs$identifiedBy.new <- fixName(occs$identifiedBy, special.char = FALSE)
occs$recordNumber.new <- colNumber(x = occs$recordNumber, noNumb = "s.n.")
occs$year.new <- getYear(occs$year, noYear = "n.d.")
occs$yearIdentified.new <- getYear(occs$yearIdentified, noYear = "n.d.")
```

Next, we format the names of the collector and identificator (function `prepTDWG()`)

```{r, eval = FALSE}
occs$recordedBy.new <- prepTDWG(occs$recordedBy.new)
occs$identifiedBy.new <- prepTDWG(occs$identifiedBy.new)
```

We then separate first and auxiliary names for multiple names and then convert
them to the TDWG format (function `tdwgNames()`). To do so, we set the argument
`out` of function `tdwgNames()` to "aux" and "first" (by default `tdwgNames()`
edits and returns all names from multiple name strings).

We also define that the symbol that will separate different names, which in our
example will be a semi-colon followed by a space.

```{r, eval = FALSE}
occs$recordedBy.aux <- sapply(occs$recordedBy.new, tdwgNames, out = "aux", sep.out = ";")
occs$recordedBy.new <- lapply(occs$recordedBy.new, tdwgNames, out = "first")
occs$identifiedBy.aux <- lapply(occs$identifiedBy.new, tdwgNames, out = "aux", sep.out = ";")
occs$identifiedBy.new <- lapply(occs$identifiedBy.new, tdwgNames, out = "first")
```

We can inspect what is the result of this separation between first and auxiliary names:

```{r, eval = FALSE}
head(occs[,c("recordedBy","recordedBy.new","recordedBy.aux")], 3)
```

It is also useful for the validation process to standardize the notation for
missing collector and identificator names. To do so, we use the function
`missName()` and again we set missing names as "s.n.".

```{r, eval = FALSE}
occs$recordedBy.new <- missName(occs$recordedBy.new, type = "collector", noName = "s.n.")
occs$identifiedBy.new <- missName(occs$identifiedBy.new, type = "identificator", noName = "s.n.")
```

For some of the operations we will perform, it is also useful to extract the
last name of the first collector, that is stored in our formatted field
`recordedBy.new`.

```{r, eval = FALSE}
occs$last.name <- lastName(occs$recordedBy.new, noName = "s.n.")
```

We can inspect what these functions are doing by comparing the original and edit
columns (only the first 15 records)

```{r, eval = FALSE}
head(cbind(occs$recordedBy, occs$recordedBy.new, occs$recordedBy.aux), n = 15)
head(cbind(occs$recordedBy, occs$last.name), n = 15)
head(cbind(occs$identifiedBy, occs$identifiedBy.new), n = 15)
head(cbind(occs$year, occs$eventDate, occs$year.new), n = 15)
head(cbind(occs$yearIdentified, occs$yearIdentified.new), n = 15)
```

These functions handle well most formats but not all of them  (e.g. name format
'A. Custódio, Filho' or date format "Jul-02"). However, this standardization
will be useful for the search of duplicated specimens across herbaria
(see below).

The final step is the standardization of the notation of collection codes, which
is stored in the field 'collectionCode'. For some reason, not all collections
store in this field their international collection codes (e.g. Index
Herbariorum) and sometimes these codes are stored differently across data
repositories. For the search of duplicate entries and th production of
check-lists (see below) it is important to standardize the codes of collections.
In __plantR__ this is done using function `getCode`:

```{r, eval = FALSE}
occs <- getCode(occs)
```

### The wrapper function `formatOcc()`

All the previous steps are important to understand the editing process of each
field. __plantR__ can execute all these steps at once using the wrapper function
`formatOcc()`:

```{r, eval = FALSE}
occs1 <- fixField(example$data, origin = "splink")
occs1 <- formatOcc(occs1)
```

Let's compare if the output of the two approaches are the same, column by column:

```{r, eval = FALSE}
identical(occs$recordedBy.new, occs1$recordedBy.new)
identical(occs$identifiedBy.new, occs1$identifiedBy.new)
identical(occs$year.new, occs1$year.new)
identical(occs$yearIdentified.new, occs1$yearIdentified.new)
identical(occs$last.name, occs1$last.name)
rm(occs1)
```

Yes! So, the new data frame contains the original and edited/formatted
information regarding the name of the collector and of the identificator, the
dates of collection and identification, and collection number.

## Editing locality information

One important step to find missing geographical coordinates and to validate the
coordinates provided with the occurrence is to standardize the fields containing
locality information, namely "country", "stateProvince", "municipality" and
"locality".

__plantR__ has a function to edit and standardize locality fields: function
`fixLoc()`. By default, this function formats all four locality fields
simultaneously (returns the entry data.frame with the new columns), but the user
can choose one field at a time by changing the function argument 'admin.levels'
(in this case, the function returns a vector). However, some of the editing
processes become more complete if all the information is available for the four
fields.

To exemplify, we will use all locality fields:

```{r, eval = FALSE}
occs <- fixLoc(occs,
               admin.levels = c("country","stateProvince","municipality","locality"),
               scrap = TRUE)
```

Note that we performed the editing of the locality fields using the argument
`scrap = TRUE`. This argument controls the search for missing information from
the field locality (i.e. text mining). It also performs some extra editing and
cropping of the locality field in order to obtain more standardized locality
descriptions. If the country, state, and municipality fields are given, they
remain unaltered. Only missing information in these fields is completed by the
editing and scrapping process.

Although the search for missing localities generally results in empty fields
(i.e. NAs), it does not mean that the information retrieved from this search is
accurate. It depends on the information being actually available in the field
'locality' and how it is arranged. To make sure that the missing information
obtained is indeed a locality, we need to crosscheck it with a gazetteer. In
__plantR__, the search for missing information from a gazetteer is based on a
standard locality string. This string simply is the concatenation of the country,
state, municipality and locality fields, at the best resolution available. This
string is created using the function `strLoc()`:

```{r, eval = FALSE}
locs <- strLoc(occs)
head(locs, 5)
```

If the municipality exists for a given state and country, then it is deemed as
being a good locality name, and the locality string associated with it is given
priority for the validation of the locality information (see below). If there is
missing information, then the alternative locality string (obtained using
argument `scrap` of function `fixLoc()`) is used as a final attempt to search for
missing information in the gazetteer. If both these alternatives do not work, then
the upper administrative level available is used as the reference locality
information.

The notation of locality information varies a lot, and there are many mistakes
regarding the notation of some localities (e.g. "Balneário do Camboriú" instead
of "Balneário Camboriú"). Therefore, it is useful to further simplify the
locality strings, by reducing all name variants into the same locality string.
This simplification is performed by the function `prepLoc()`:

```{r, eval = FALSE}
locs$loc.string  <- prepLoc(locs$loc.string) # priority string
locs$loc.string1 <- prepLoc(locs$loc.string1) # alternative string
locs$loc.string2 <- prepLoc(locs$loc.string2) # alternative string
```

After the construction and simplification of the locality strings, we can
finally cross it with the gazetteer, using function `getLoc()`.

```{r, eval = FALSE}
locs <- getLoc(locs, gazet = "plantR")
```

Some of the locality strings were retrieved in the default __plantR__ gazetteer at
the locality level (e.g. park, farm). The gazetteer is more complete for Latin
America and has much more information at the locality level for Brazil.
Therefore, info retrieval at the locality level should be biased towards
specimens collected in Brazil. You can use the argument `gazet` to use your
personal gazetteer instead of __plantR__ default, as long as it contains the
same fields.  <!-- Which fields? does plantR standardize a foreing gazetteer?-->
Note that the function also returns the geographical coordinates from the
gazetteer. Note as well that the edited version of the localities is different
from the original localities regarding their resolution (see details in the next
section, 'Data validation'). <!-- ö add link to section-->

We merge the data frame with the previous data processing (function
`formatOcc()`) with the output of the locality data processing:

```{r, eval = FALSE}
occs <- cbind.data.frame(occs, locs[, c("loc","loc.correct","latitude.gazetteer","longitude.gazetteer","resolution.gazetteer")])
```
### The wrapper function `formatLoc()`

As before, we provide a function to execute the previous steps at once:

```{r, eval = FALSE}
occs1 <- fixField(example$data, origin = "splink")
occs1 <- formatLoc(occs1)
```

### Getting correct locality names: function `getAdmin()`

It may be useful to trace back the full names of the localities
retrieved from the gazetteer. This can be performed using the function
`getAdmin()`, which returns the names of the subdivisions of each locality:

```{r, eval = FALSE}
head(getAdmin(occs))
```


## Editing geographical coordinates

Previous to the validation of the original geographical coordinates, it is
important to make sure that they are given and if they are in the required
format: non-zero, non-NA [decimal degrees](https://en.wikipedia.org/wiki/Decimal_degrees),
with decimal digits separated by points.

Function `prepCoord()` transforms the coordinates into decimal degrees and add the columns "decimalLatitude.new"  and "decimalLongitude.new". 

```{r, eval = FALSE}
occs <- prepCoord(occs)
```

Geographical coordinates are often missing or are provided in a format that the
function `prepCoord()` cannot convert to decimal degrees. For the dataset we are
using in this tutorial, we can inspect the proportion of occurrences without
geographical coordinates:

```{r, eval = FALSE}
table(!is.na(occs$decimalLatitude.new))/dim(occs)[1]
```

As we can see, 20% of the occurrences records have no coordinates. Therefore,
one may want to use the coordinates obtained from the gazetteer to replace the
missing coordinates. In __plantR__ we use the function `getCoord()` to do this
procedure. This function also flags the origin and the probable precision of
the original coordinates:

```{r, eval = FALSE}
occs <- getCoord(occs)
table(!is.na(occs$decimalLatitude.new))/dim(occs)[1]
```

Now, missing coordinates were obtained from a gazetteer and there is a coordinate at the best resolution available for almost all occurrences.

### The wrapper function `formatCoord()`

Similarly to the functions `formatOcc()` and `formatLoc` from the previous
editing steps, we provide a function that perform all the edits related to the
geographical coordinates at once, the function `formatCoord()`. Because getting
missing coordinates from the gazetteer depends on the editing of the locality
information, we need to run the before `formatLoc()` runnig `formatCoord()`:

```{r, eval = FALSE}
occs1 <- fixField(example$data, origin = "splink")
occs1 <- formatLoc(occs1)
occs1 <- formatCoord(occs1)
```

## Editing species taxonomic information

### Species names format: function `prepSpecies()`
Although we downloaded occurrences for only two species names (i.e.
\italic{Trema micrantha} and \italic{Casearia sylvestris}), the function
`rspeciesLink()` returned (as required) all synonyms accepted by the Brazilian
Flora 2020 (\url{http://floradobrasil.jbrj.gov.br/reflora/listaBrasil}). In addition, the speciesLink network
(\url{http://splink.cria.org.br/}) stores the information as provided by the
collections, which may vary in the way the scientific names are stored. For data
downloaded from GBIF (\url{https://www.gbif.org/}) this step may be unnecessary
since GBIF already stores data in a more standardized way.

The `plantR` function ```prepSpecies``` performs several edits, including the
isolation of taxonomic rank abbreviations, the detection of name modificators
("cf." and "aff.") and a suggestion for the name status:

```{r, eval = FALSE}
sort(table(occs$scientificName))
occs <- prepSpecies(occs)
sort(table(occs$scientificName.new))
```

Note that the number of names has decreased, but there are still many different names than the two names used in the search. The possible status of those name are stored in the new column ```scientificNameStatus```

```{r, eval = FALSE}	
sort(table(occs$scientificNameStatus))
```

### Species synonyms and spelling: function `formatSpecies()`
Although the function `prepSpecies` presented above formatted the species names,
there are still many more names than the ones we downloaded. Most of them are
names at the infra-specific level, but others are probably synonyms,
ortographical variants or even typos. There are R packages that check species
nomenclature (e.g. `taxize`, `Taxonstand`, and `WorldFlora`). For species listed
in the Brazilian Flora 2020, there is also the package `flora`, which follow the
accepted nomenclature of the Brazilian Flora 2020 project. `plantR` uses the
functionalities of some of these packages to inspect possible suggestions for
species names, through the function `formatSpecies`:

```{r, eval = FALSE}
occs <- formatSpecies(occs, db = c("bfo", "tpl"), sug.dist = 0.85)
table(occs$suggestedName)
table(occs$notes)
```

The final output of the function provide the valid names for the names that were retrieved in the two databases selected. The function also returns which names were replaced or corrected (i.e. typos). In addition, the flag 'check +1 accepted' may represent an indication of possible homonyms, i.e., different species with the same binomial but different authorities. Together with names there were not found in both databases, those possible homonyms may deserve closer attention. 

Note that there are still more names than the ones used to search for
occurences. Some of these differences are due to differences in the assignnemt
of synonyms between speciesLink and the Brazilian Flora interface used here, the
package `flora`.

For our example we decided to replace all edited species names (i.e.
'scientificName.new') by the suggested species names from the function
`formatSpecies` (i.e. 'scientificName.new'). However, __plantR__ does not
execute this step automatically and the decision to do it should be taken by the
user:

```{r, eval = FALSE}
occs$scientificName.new <- occs$suggestedName
```

### Botanical family synonyms and standardization: function `formatFamily`
The classification of the taxonomic confidence in species determination of each
occurrence is currently performed based on a global list of taxonomists per
family (see details below). Because different plant classification systems can
use different names to the same family, we need to standardize family names. The
standard used by __plantR__ to obtain valid family names is the APG IV and the PPG
I, which can be obtained using the function `formatFamily()`:

```{r, eval = FALSE}
occs <- formatFamily(occs)
```

Note that the function return warnings in the case of conflicts on family names between the original occurrences and the APG IV/PPG I family list. Some are just differences in the list of names accepted from different classification systems, but some may represent errors.

### The wrapper function `formatTax()`

As for the other parts of the data editing and standardization, we provide a simple wrapper function that executes the steps above at once:

```{r, eval = FALSE}
occs1 <- fixField(example$data, origin = "splink")
occs1 <- formatTax(occs1)
```

<br/><br/>

# Data validation

In __plantR__, all validation steps add new columns to the occurrence data,
flagging possible problems. Depending on the study aims and spatial scale, one
can choose to try to correct some of the problems or drop them from the final
data set.

## Locality validation: function `validateLoc()`

The editing process of locality information and its comparison against the
gazetteer return the localities (and coordinates) at the best resolution
available. In this comparison, much information provided at the locality level
is only retrieved at the municipality level, which is expected due to the
completeness of the gazetteer used (not all place names are stored in the
standard __plantR__ gazetteer at the locality level). But many of them are only retrieved at state/province level, meaning that fields containing state and municipality information may need to be checked.

In __plantR__ the resolution of the locality information provided with the
specimen and the one found in the gazetteer are described using the function
`validateLoc()`, which compares the two resolutions and stores the result of this comparison in a new column called `'loc.check'`:

```{r, eval = FALSE}
occs <- validateLoc(occs)
unique(occs$loc.check)
```

In this column, specimens for which the locality provided could not be found in
the gazetteer at the same resolution are flagged with a "check_...". In these
cases, the locality resolution is downgraded until a locality is found in the
gazetteer. In the case that even the country is not found, then the locality is
flagged as "no_info". We also flag all the specimens that retained their
resolution (i.e. "ok_same_resolution") and those that could be retrieved at a
better locality resolution, also flagged with an "ok_" (e.g.
'ok_state2municipality': a record which had its original resolution at the 'stateProvince' level is now at the 'municipality' level).

Note that many occurrences were flagged with a "check_...". The class 
"check_local.2municip." should not be a problem, since the internal __plantR__
gazetteer does not contain a comprehensive list of names at the locality level.
However, other "check_..." classes (e.g. "check_local.2country") may indicate
missing information or typos that may need some more careful inspection.


## Geographical validation: function `validateCoord()`

Check here other possible steps that can use __coordinateCleaner__ or other packages

### Flag occurrences from cultivated individuals: function `getCult()`

Function `getCult()` flags cultivated or possibly cultivated records in a new column 

```{r, eval = FALSE}
antes <- names(occs)
occs <- getCult(occs)
despues <- names(occs)
setdiff(despues, antes)
table(occs$cult.check)

```

### Load and inspect the __plantR__ default world map


### Validate original coordinates at country, state and county level


### Coordinates falling into the sea or bays

### How distant original coordinates are from the county centroid?

### Verification of inverted and swapped coordinates

### Flagging based on coordinate resolution and distance from the target county

### Replacing coordinates according to the verified classes

### Flag possible spatial outliers

## Confidence level of species determinations: function `validateTax()`

Next step is to perform the classification of the species identification of each occurrence according to their taxonomic confidence level.

```{r, eval = F}
occs <-  validateTax(occs)
table(occs$tax.check)/dim(occs)[1]
```

As expected, only ca. 15% of the specimens were identified by a family specialist. Note that the function also returns a list with up to 10 names in the TDWG format that have more identifications. Maybe this name could represent a missing taxonomist from the __plantR__ database of plant taxonomists. If this is the case, one can add taxonomist to the validation using the argument `miss.taxonomist`:

```{r, eval = FALSE}
occs1 <- validateTax(occs, miss.taxonomist = c("Salicaceae_Hatschbach, G."))
table(occs1$tax.check)/dim(occs)[1]
```

This is not the optimal example because Gerdt (Guenther) Hatschbach was not a Salicaceae specialist. However, he provided determinantions for many different families outside his speciality, often referred to as a generalist. There are some names of generalists in the __plantR__ default taxonomist database, and those names can be included in the taxonomic validation through the arguments `generalist`. However, this list of generalist names is biased towards South America, particularly Brazil.

<br/><br/>

## Duplicated specimens

### Prepare to merge: function `prepDup()`

First we need to prepare the dataset for the duplicate search. The function 
`prepDup` basically creates concatenated strings with different set of information, which will be used in the search. Different combinations of fields can be used to generate these search strings, through the argument `comb.fields`:

```{r, eval = FALSE}
dups <- prepDup(occs, 
                comb.fields = list(c("family","col.last.name","col.number","municipality"),
     c("family","col.last.name","col.number","col.year")))
```

Note that we used the default arguments of the `prepDup` function, which exclude from the search the strings without collector name, number or year (e.g. 's.n.' or 's.d.'), as well as missing information for these columns (i.e. NAs). If one decided to include those strings in the search, the number of specimens that will pass the duplicate search will increase but the chances of finding false duplicates (e.g. Salicaceae + s.n. + s.n. + Ubatuba or Salicaceae + s.n. + s.n. + s.d.) increase as well.

### Find duplicates across collections: function `getDup()`

Next, we can actually perform the search for duplicated specimens using the function `getDup`:

```{r, eval = FALSE}
dups <- getDup(dups)
head(dups[order(dups$dup.ID),],6)
table(dups$dup.prop)
```
As a result we found about 5300 specimens with a high chance of representing true duplicates, i.e. the proportion of search strings shared between them is maximum (dup.prop = 1). Other ~300 specimens had only one search string in common. Moreover, we have indication of possible ~4600 unicates, and for other ~6800 specimens we could not check for dupicates (i.e. all search strings used have missing information).

Note that if there are duplicated entries (i.e. same accession number from the same collection) both are listed within the accession number grouped in the new column 'dup.ID'.

It is important to notice that these duplicate search results are only indications. First of all, the retrieval of duplicates depends on the dataset itself: if the collection where the duplicate was deposited is not within the dataset (e.g. collection is not in speciesLink or GBIF), the duplicate cannot be retrieved for obvious reasons. But other issues may change the number of unicates and duplicates found. If the search string is too flexible (e.g. only collector name and number), false duplicates may be retrieved if collector names are common (e.g. 'Silva', 'Santos' or 'Lima' for Portuguese family names) and collector numbers are low. So having more than one search string with at least 3 combinations of information descreases the chnce of false duplicates. On the other hand, we may have false unicates due to differences in the notation among collections, which could not be solved by __plantR__ (e.g. Mattos-Silva, L.A. vs. Silva, L.A.M.), or typos (e.g. Hoffmannsegg, J.C. vs. Hoffmannseg, J.C.). Finally, many duplicates may still exist but due to missing information (e.g. collecor number or collection year or locality), they can not enter the duplicate search.  

### Homogenizing the information within duplicates: function `mergeDup()`

Since the amount and quality of the information among collectiors may vary, one
may want to homogenize the information within the duplicates. These
homogenization can be carried out regarding the specimens identification or
their locality and geographical coordinates. First, we need to combine the
results of the duplicate search with out 'master' data frame:

```{r, eval = FALSE}
occs <- cbind.data.frame(occs, 
                         dups[,c("numTombo","dup.ID","dup.numb","dup.prop")],
                         stringsAsFactors = FALSE)
```

Next, we use function `mergeDup` to perform the homogenization itself, which aims at expanding the best-quality information found across all specimens of each group of duplicate. 

```{r, eval = FALSE}
occs <- mergeDup(occs)
table(occs$tax.check, occs$tax.check1)
```

In this example, we show that the function was able to retrieve high-confidence species identifications for about 700 specimens with low or unknown confidence levels. There was also an improvement on the stats regarding the geographical and locality checks (i.e. columns 'geo.check' vs. 'geo.check1' and 'loc.check' vs. 'loc.check1')

Note that we used the function defaults, which created new columns for the merged information. If one wants to save the new information in the same columns, the argument `overwrite` should be set to `TRUE`.

### Removing duplicates after homogenization: function `rmDup()`

`plantR` provides a simple function for the (fast) removal of duplicates from the data. This procedure should only be performed if the user deems it necessary and after the information among groups of duplicates has been homogenized. Only the first specimen of each group of duplicates is maintained and the non-homogenized information contained in the other specimens is lost. 

```{r, eval = FALSE}
dim(occs)
occs <- rmDup(occs)
dim(occs)
```

### The wrapper function `validateDup()`

As the stesp above related to duplicated specimens can be performed at once, using the function `validateDup()`:

```{r, eval = FALSE}
occs1 <- fixField(example$data, origin = "splink")
occs1 <- formatLoc(occs1)
occs1 <- validateDup(occs1)
```


<br/><br/>

# Data summary and export

## Number of specimens, collections, species and other descriptors

```{r, eval = FALSE}
summaryData(occs)
```

## Summary of validation flags and other issues

```{r, eval = FALSE}
summaryFlags(occs)
```

## Generating checklists

```{r, eval = FALSE}
checkList(occs)
```

## Saving the occurrence data

```{r, eval = FALSE}
saveData(occs, by = "family")
```


### Saving outputs to the format of other packages: *MODEL-R* and *ConR*
[TO BE IMPLEMENTED]
