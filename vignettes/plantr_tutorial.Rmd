---
title: "plantR Tutorial"
date: "`r Sys.Date()`"
output:
    rmarkdown::html_vignette:
        toc: true
        number_sections: true
    md_document:
      variant: gfm
vignette: >
  %\VignetteEncoding{UTF-8}
  %\VignetteIndexEntry{plantR tutorial}
  %\VignetteEngine{knitr::rmarkdown}
    \usepackage[utf8]{inputenc}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo = FALSE, message= TRUE}
#aqui carrega o pacote que está no seu HD, não precisa instalar ele para trabalhar
devtools::load_all()
```

# Introduction

# Data entry

## Tools available for data download

You can download species occurrence data directly from R, using existing functions of other packages or function provided by `plantR`. For this tutorial, we are going to use the function `rspeciesLink` that downloads data from [CRIA](http://www.cria.org.br/) (Centro de Referência em Informação Ambiental). You can check a detailed tutorial of how to download data from different sources here. #INCLUDE LINK TO SARA'S DETAILED TUTORIAL# 

You can also use files containing personal data or data downloaded manually from other online data repositories, as long as the haeaders of the files match those accepted in `plantR` (e.g. DarwinCore). See function `fixField()` below for details.
	
## Downloading the content for each collection

We will use as an example a dataset downloaded from speciesLink, using the function `rspeciesLink` which allows a wide variety of ways on how to search for data. In this tutorial, we will use data for four very common Neotropical trees:

```{r, eval = FALSE}
spp <- c("Trema micrantha",
        "Myrcia splendens",
        "Casearia sylvestris")
```

After definig the list of species we want to download data, we proceed to the download itself. Here we will use all herbarium plant specimens (i.e. vouchers) for the names listed above and their synonyms accepted in the Brazlian Flora 2020 project:

```{r, eval = FALSE}
example <- rspeciesLink(scientificName =  spp,
                     Scope = "plants",
                     basisOfRecord = "PreservedSpecimen",
                     Synonyms = "flora2020"
                     )
```

If the connection to the server fails, you can use the data downloaded usign the same specifications in 28/04/2020: 

```{r, eval = FALSE}
data(example)
```


# Data processing

## Setting up the input data: function `fixField()`

Before we can start our data processing and validation routines, we need to sure that our input data has all the required fields.


Then, we use the function `fixField()` to set up the require and optional fields and to drop fields without essential information for the data processing and validation. We save the output of the function with a different name ('occs').

```{r, eval = FALSE}
occs <- fixField(example, origin = "jabot")
```

Note that the function returns some warning meassages. It is **VERY** important to carefully understand these warnings before we can continue. 

The first warning says that the name of the column header 'scientifname', provided in the input data, was replaced by the standard name 'scientificName', the standard name used by `plantR`. The second warning also reports that a header name was replaced by a standard header name, 'occurrenceID' in this case. Third warning is less important because it relates to optional fields. The last warning is more important, since they may indicate typos in the names of important hearders.

## Standardizing names, collector number and dates: function `formatOcc()`

Particularly when working with data coming from multiple secondary sources, it is important to standardize the notation used by different collections and sometimes by different collectors within the same collection.

We first create the new columns that will receive the edited fields.

```{r, eval = FALSE}
occs$recordedBy.new = occs$recordedBy
occs$recordNumber.new = occs$recordNumber
occs$identifiedBy.new = occs$identifiedBy
occs$year.new = occs$year
occs$dateIdentified.new = occs$dateIdentified
```

For the year of collection, sometimes the information is stored on the field 'eventDate' and not on the field 'year'. So, we replace all missing information from the field 'year' by the informations stored in the field 'eventDate'

```{r, eval = FALSE}
occs$year.new[is.na(occs$year.new)] = occs$eventDate[is.na(occs$year.new)]
```

We then prepare the new fields we created using functions `fixName()`, `colNumber()` and `getYear()`. We chose to remove all species characters from authors and identicador names (argument `special.char = FALSE`), which is the indicated option for further data processing and validation. We also set the characters that will represent occurrences without number of collection ("s.n.") and without the year of collection and identification ("n.d.").  

```{r, eval = FALSE}
occs$recordedBy.new = unlist(lapply(occs$recordedBy.new, fixName, special.char = FALSE))
occs$identifiedBy.new = unlist(lapply(occs$identifiedBy.new, fixName, special.char = FALSE))
occs$recordNumber.new = unlist(lapply(occs$recordNumber.new, colNumber, noNumb = "s.n."))
occs$year.new = unlist(lapply(occs$year.new, getYear, noYear = "n.d."))
occs$dateIdentified.new = unlist(lapply(occs$dateIdentified.new, getYear, noYear = "n.d."))
```

Next, we format the names of the collector and identificator (function `formatName()`)
```{r, eval = FALSE}
occs$recordedBy.new = unlist(lapply(occs$recordedBy.new, formatName))
occs$identifiedBy.new = unlist(lapply(occs$identifiedBy.new, formatName))
```

We then separate first and auxiliary names for multiple names and then convert them to the TDWG format (function `tdwgNames()`). To do so, we set the argument 'out' of function `tdwgNames()` to "aux" and "first" (by default `tdwgNames()` edits and returns all names from multiple name strings).

We also define that the symbol that will separate different names, which in our example will be a semi-colon followed by a space.

```{r, eval = FALSE}
occs$recordedBy.aux = unlist(lapply(occs$recordedBy.new, tdwgNames, out = "aux", sep.out = "; "))
occs$identifiedBy.aux = unlist(lapply(occs$identifiedBy.new, tdwgNames, out = "aux", sep.out = "; "))
occs$recordedBy.new = unlist(lapply(occs$recordedBy.new, tdwgNames, out = "first"))
occs$identifiedBy.new = unlist(lapply(occs$identifiedBy.new, tdwgNames, out = "first"))
```

We can inspect what is the result of this separation between first and auxiliary names:
```{r, eval = FALSE}
head(occs[,c("recordedBy","recordedBy.new","recordedBy.aux")], 3)
```

It is also useful for the validation process to standardize the notation for missing collector and identificator names. To do so, we use the function `missName()` and again we set missing names as "s.n.".

```{r, eval = FALSE}
occs$recordedBy.new = missName(occs$recordedBy.new, type = "collector", noName = "s.n.")
occs$identifiedBy.new = missName(occs$identifiedBy.new, type = "identificator", noName = "s.n.")
```

For some of the operations we will perform, it is also useful to extract the last name of the first collector, that is stored in our formated field 'recordedBy.new'

```{r, eval = FALSE}
occs$last.name = unlist(lapply(occs$recordedBy.new, lastName))
```

We can inspect what these functions are doing by comparing the original and edit columns (only the first 15 records)

```{r, eval = FALSE}
head(cbind(occs$recordedBy, occs$recordedBy.new, occs$recordedBy.aux), n = 15)
head(cbind(occs$recordedBy, occs$last.name), n = 15)
head(cbind(occs$identifiedBy, occs$identifiedBy.new), n = 15)
head(cbind(occs$year, occs$eventDate, occs$year.new), n = 15)
head(cbind(occs$dateIdentified, occs$dateIdentified.new), n = 15)
```

Note that the function handles well most formats but not all of them  (e.g. name format 'A. Custódio, Filho' or date format "Jul-02"). Although not perfect, this standardization will be very useful for the search of duplicated specimens across herbaria (see below).

All the previous steps are important to understand the edtiton of each field. But, `plantR` can execute all these steps at once using the wrapper function `formatOcc()`:

```{r, eval = FALSE}
occs1 = fixField(example, origin = "jabot")
occs1 = formatOcc(occs1)
```

Let's compare if the output of the two approaches are the same, column by column:

```{r, eval = FALSE}
table(occs$recordedBy.new == occs1$recordedBy.new)
table(occs$identifiedBy.new == occs1$identifiedBy.new)
table(occs$year.new == occs1$year.new)
table(occs$dateIdentified.new == occs1$dateIdentified.new)
table(occs$last.name == occs1$last.name)
rm(occs1)
```

Yes! So, the new data frame created contain the original and edited/formatted information regarding the name of the collector and of the identificator, the dates of collection and identification, and number of collection. 


## Editing locality information and crossing with gazetteer information: function `formatLoc()`

One important step to find missing geographical coordinates and to validate those coordinates provided with the occurrence is to standardize the fields containing locatity information, namely "country", "stateProvince", "municipality" and "locality".

`plantR` have a function to edit and standardize locality fields: function `fixLoc()`. By default, this function formats all four locality fields simultaneously (returns the entry data.frame with the new columns), but the user can chose one field at a time by changing the function argument 'adm.levels' (returns a vector). However, some of the editing processes become more complete if all the information is available for the four fields.

To exemplify, we will use all locality fields:

```{r, eval = FALSE}
locals = fixLoc(occs, adm.levels = c("country","stateProvince","municipality","locality"), scrap = TRUE)
locals1 = fixLoc(occs, adm.levels = c("country","stateProvince","municipality","locality"), scrap = FALSE)
```
Note that we performed two different ways to edit the locality fields. The argument 'scrap' controls the search for missing municipality information from the field locality. It also performs some extra editing and croping of the locality field in order to obtain more standardized locality descriptions. We can compare the original and the edited locality fields:    
	
```{r, eval = FALSE}	
head(cbind(occs$country, locals$country.new, locals1$country.new), n = 5)
head(cbind(occs$stateProvince, locals$stateProvince.new, locals1$stateProvince.new), n = 5)
head(cbind(occs$municipality, locals$municipality.new, locals1$municipality.new), n = 5)
head(cbind(occs$locality, locals$locality.new, locals$locality.scrap, locals1$locality.new), n = 5)
```

Note that if the country, state and municipality fields are given, they remain unaltered. Only missing information in this fields are completed bu the editing and scrapping process.

Although the search for missing municipalities results in no NAs, it does not mean that the information retrieved are valid. It depends if the information is actually available in the locality field and how it is arranged. To make sure that the missing information obtained is indeed valid, we need to cross it with a gazetteer. If the municipality exists for a given state and country, then it is deemed as being a valid municipality, which will be further used on the coordinate validation process. If it doesnot exist, then a higher administrative level is used as the reference 'resolution' of the locality information. 

#### ADD ARGUMENT TO GET THE FILE CONTAINING THE DICTIONARY ####

```{r, eval = FALSE}	
locals  = getLoc(locals)
locals1 = getLoc(locals1)
```	

Note that the edited version of the localities has some improve regarding the number of localities provided at "stateProvince" level and that some of the localities provided were retrieved in the default gazetteer. 

Finally, we merge the data frame with the previous data processing (function `formatOcc()`) with the output of the locality data processing:

```{r, eval = FALSE}	
occs  = cbind.data.frame(occs, locals[,c("loc.correct","latitude.gazetteer","longitude.gazetteer","resolution.gazetteer","loc.check")])
```	

Besides the coordinates of all localities at the best locality resolution available, these procedure also performs a initial checking of the locality names provided, which is stored in the column 'loc.check': 

```{r, eval = FALSE}	
table(occs$loc.check)
```	

In this column, specimens for which the locality information provided could not be found in the gazetteer are flagged with a "check_" and thus they have their resolution downgraded. We also flag all the specimens that retained their resoltution (i.e. "ok_same") and those that could be validate at a better locality resolution, flagged with a "ok_" (e.g. 'ok_state2municipality': 'stateProvince' level that is now at the 'municipality' level).

## Editing original coordinates and defining working coordinates: function `formatCoord()`

Previous to the validation of the orginal geographical coordinates, it is important to make sure that they are given and if they are in the required format: non-zero, non-NA [decimal degrees](https://en.wikipedia.org/wiki/Decimal_degrees), with decimal digits separated by points.

```{r, eval = FALSE}	
occs = prepCoord(occs)
```	

Geographical coordinates are often missing or are provided in a format that the function `prepCoord` cannot convert to decimal degrees. For the dataset we are using in this tutorial, we can inspect the proportion of occurrences without geographical coordinates: 

```{r, eval = FALSE}	
table(!is.na(occs$decimalLatitude.new))/dim(occs)[1]
```	

As we can see, only about 30% of the occurrences records have coordinates. Therefore, one may want to use the coordinates obtained from the gazetteer to replace the missing coordinates. In `plantR` we use the function `workCoord` to do this procedure. This function also flags the origin and the probable resolution of the original coordinates: 

```{r, eval = FALSE}	
occs = workCoord(occs)
```	

# Data validation

## Taxonomic validation: function `validateTax()`

### Species names spelling, format and synonyms 


### Confidence level of species determinations

	
## Geographical validation: function `validateCoord()`
	

# Duplicated specimens (FUNCTIONS NOT CREATED YET)

## Prepare to merge: function `dupPrep()`
	
## Find duplicates across collections: function `dupSearch()`
	
## Homogenizing information within duplicates: function `dupInfo()`
	

# Data description  (NEED TO CHECK)

## Number of collections, specimens and duplicates retrieved: 
	
